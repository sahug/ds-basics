{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Machines Algorithm\n",
    "Gradient boosting refers to a class of ensemble machine learning algorithms that can be used for classification or regression predictive modeling problems.\n",
    "\n",
    "Gradient boosting is also known as gradient tree boosting, stochastic gradient boosting (an extension), and gradient boosting machines, or GBM for short.\n",
    "\n",
    "Ensembles are constructed from decision tree models. Trees are added one at a time to the ensemble and fit to correct the prediction errors made by prior models. This is a type of ensemble machine learning model referred to as boosting.\n",
    "\n",
    "Models are fit using any arbitrary differentiable loss function and gradient descent optimization algorithm. This gives the technique its name, “gradient boosting,” as the loss gradient is minimized as the model is fit, much like a neural network.\n",
    "\n",
    "One way to produce a weighted combination of classifiers which optimizes [the cost] is by gradient descent in function space\n",
    "\n",
    "— Boosting Algorithms as Gradient Descent in Function Space, 1999.\n",
    "\n",
    "Naive gradient boosting is a greedy algorithm and can overfit the training dataset quickly.\n",
    "\n",
    "It can benefit from regularization methods that penalize various parts of the algorithm and generally improve the performance of the algorithm by reducing overfitting.\n",
    "\n",
    "There are three types of enhancements to basic gradient boosting that can improve performance:\n",
    "\n",
    " - Tree Constraints: such as the depth of the trees and the number of trees used in the ensemble.\n",
    " - Weighted Updates: such as a learning rate used to limit how much each tree contributes to the ensemble.\n",
    " - Random sampling: such as fitting trees on random subsets of features and samples.\n",
    " \n",
    "The use of random sampling often leads to a change in the name of the algorithm to “stochastic gradient boosting.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Scikit-Learn API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.0\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# test classification dataset\n",
    "from sklearn.datasets import make_classification\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.898 (0.025)\n"
     ]
    }
   ],
   "source": [
    "# evaluate gradient boosting algorithm for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "\n",
    "# define the model\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "# define the evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# evaluate the model on the dataset\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# report performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 1\n"
     ]
    }
   ],
   "source": [
    "# make predictions using gradient boosting for classification\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "\n",
    "# define the model\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "# fit the model on the whole dataset\n",
    "model.fit(X, y)\n",
    "\n",
    "# make a single prediction\n",
    "row = [0.2929949, -4.21223056, -1.288332, -2.17849815, -0.64527665, 2.58097719, 0.28422388, -7.1827928, -1.91211104, 2.73729512, 0.81395695, 3.96973717, -2.66939799, 3.34692332, 4.19791821, 0.99990998, -0.30201875, -4.43170633, -2.82646737, 0.44916808]\n",
    "yhat = model.predict([row])\n",
    "\n",
    "# summarize prediction\n",
    "print('Predicted Class: %d' % yhat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# test regression dataset\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=7)\n",
    "\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -62.487 (3.273)\n"
     ]
    }
   ],
   "source": [
    "# evaluate gradient boosting ensemble for regression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=7)\n",
    "\n",
    "# define the model\n",
    "model = GradientBoostingRegressor()\n",
    "\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# evaluate the model\n",
    "n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "# report performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 37\n"
     ]
    }
   ],
   "source": [
    "# gradient boosting ensemble for making predictions for regression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=7)\n",
    "\n",
    "# define the model\n",
    "model = GradientBoostingRegressor()\n",
    "\n",
    "# fit the model on the whole dataset\n",
    "model.fit(X, y)\n",
    "\n",
    "# make a single prediction\n",
    "row = [0.20543991, -0.97049844, -0.81403429, -0.23842689, -0.60704084, -0.48541492, 0.53113006, 2.01834338, -0.90745243, -1.85859731, -1.02334791, -0.6877744, 0.60984819, -0.70630121, -1.29161497, 1.32385441, 1.42150747, 1.26567231, 2.56569098, -0.11154792]\n",
    "yhat = model.predict([row])\n",
    "\n",
    "# summarize prediction\n",
    "print('Prediction: %d' % yhat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore Number of Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">10 0.834 (0.035)\n",
      ">5000 0.925 (0.022)\n",
      ">500 0.921 (0.022)\n",
      ">1000 0.924 (0.021)\n",
      ">100 0.897 (0.025)\n",
      ">50 0.877 (0.032)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# explore gradient boosting number of trees effect on performance\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from matplotlib import pyplot\n",
    "% matplotlib inline\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "    X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "    return X, y\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    # define number of trees to consider\n",
    "    n_trees = [10, 50, 100, 500, 1000, 5000]\n",
    "    for n in n_trees:\n",
    "        models[str(n)] = GradientBoostingClassifier(n_estimators=n)\n",
    "    return models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    # define the evaluation procedure\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    # evaluate the model and collect the results\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    # evaluate the model\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    # store the results\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    # summarize the performance along the way\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore Number of Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0.9 0.903 (0.029)\n",
      ">1.0 0.898 (0.025)\n",
      ">0.3 0.897 (0.033)\n",
      ">0.5 0.905 (0.027)\n",
      ">0.1 0.873 (0.024)\n",
      ">0.7 0.901 (0.029)\n",
      ">0.4 0.899 (0.027)\n",
      ">0.6 0.908 (0.024)\n",
      ">0.2 0.894 (0.029)\n",
      ">0.8 0.906 (0.031)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# explore gradient boosting ensemble number of samples effect on performance\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import arange\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from matplotlib import pyplot\n",
    "% matplotlib inline\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "    X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "    return X, y\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    \n",
    "    # explore sample ratio from 10% to 100% in 10% increments\n",
    "    for i in arange(0.1, 1.1, 0.1):\n",
    "        key = '%.1f' % i\n",
    "        models[key] = GradientBoostingClassifier(subsample=i)\n",
    "        \n",
    "    return models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    \n",
    "    # define the evaluation procedure\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    \n",
    "    # evaluate the model and collect the results\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    \n",
    "    # evaluate the model\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    \n",
    "    # store the results\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    \n",
    "    # summarize the performance along the way\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "    \n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore Number of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">3 0.896 (0.028)\n",
      ">12 0.895 (0.029)\n",
      ">2 0.884 (0.034)\n",
      ">5 0.896 (0.029)\n",
      ">13 0.898 (0.023)\n",
      ">15 0.901 (0.030)\n",
      ">7 0.897 (0.031)\n",
      ">11 0.898 (0.029)\n",
      ">9 0.901 (0.028)\n",
      ">6 0.894 (0.028)\n",
      ">20 0.900 (0.025)\n",
      ">8 0.899 (0.028)\n",
      ">10 0.896 (0.026)\n",
      ">4 0.892 (0.029)\n",
      ">19 0.898 (0.028)\n",
      ">16 0.897 (0.029)\n",
      ">1 0.869 (0.030)\n",
      ">18 0.899 (0.027)\n",
      ">17 0.901 (0.028)\n",
      ">14 0.901 (0.027)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# explore gradient boosting number of features on performance\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from matplotlib import pyplot\n",
    "% matplotlib inline\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "    X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "    return X, y\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    \n",
    "    # explore number of features from 1 to 20\n",
    "    for i in range(1,21):\n",
    "        models[str(i)] = GradientBoostingClassifier(max_features=i)\n",
    "    return models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    \n",
    "    # define the evaluation procedure\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    \n",
    "    # evaluate the model and collect the results\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "\n",
    "for name, model in models.items():\n",
    "    \n",
    "    # evaluate the model\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    \n",
    "    # store the results\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    \n",
    "    # summarize the performance along the way\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "    \n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0.0100 0.832 (0.030)\n",
      ">0.0010 0.783 (0.037)\n",
      ">0.1000 0.898 (0.025)\n",
      ">0.0001 0.766 (0.050)\n",
      ">1.0000 0.906 (0.031)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# explore gradient boosting ensemble learning rate effect on performance\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "    X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "    return X, y\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    \n",
    "    # define learning rates to explore\n",
    "    for i in [0.0001, 0.001, 0.01, 0.1, 1.0]:\n",
    "        key = '%.4f' % i\n",
    "        models[key] = GradientBoostingClassifier(learning_rate=i)\n",
    "        \n",
    "    return models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    \n",
    "    # define the evaluation procedure\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    \n",
    "    # evaluate the model and collect the results\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    \n",
    "    # evaluate the model\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    \n",
    "    # store the results\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    \n",
    "    # summarize the performance along the way\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "    \n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore Tree Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">3 0.899 (0.025)\n",
      ">7 0.912 (0.025)\n",
      ">8 0.893 (0.027)\n",
      ">10 0.833 (0.036)\n",
      ">4 0.910 (0.031)\n",
      ">5 0.918 (0.027)\n",
      ">1 0.834 (0.037)\n",
      ">2 0.879 (0.029)\n",
      ">9 0.844 (0.040)\n",
      ">6 0.915 (0.029)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# explore gradient boosting tree depth effect on performance\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "    X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "    return X, y\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    \n",
    "    # define max tree depths to explore between 1 and 10\n",
    "    for i in range(1,11):\n",
    "        models[str(i)] = GradientBoostingClassifier(max_depth=i)\n",
    "    return models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    \n",
    "    # define the evaluation procedure\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    \n",
    "    # evaluate the model and collect the results\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    \n",
    "    # evaluate the model\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    \n",
    "    # store the results\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    \n",
    "    # summarize the performance along the way\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "    \n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.942000 using {'n_estimators': 500, 'subsample': 0.5, 'learning_rate': 0.1, 'max_depth': 9}\n",
      "0.501000 (0.002000) with: {'n_estimators': 10, 'subsample': 0.5, 'learning_rate': 0.0001, 'max_depth': 3}\n",
      "0.501000 (0.002000) with: {'n_estimators': 10, 'subsample': 0.7, 'learning_rate': 0.0001, 'max_depth': 3}\n",
      "0.501000 (0.002000) with: {'n_estimators': 10, 'subsample': 1.0, 'learning_rate': 0.0001, 'max_depth': 3}\n",
      "0.782667 (0.044231) with: {'n_estimators': 50, 'subsample': 0.5, 'learning_rate': 0.0001, 'max_depth': 3}\n",
      "0.781333 (0.037077) with: {'n_estimators': 50, 'subsample': 0.7, 'learning_rate': 0.0001, 'max_depth': 3}\n",
      "0.733000 (0.053377) with: {'n_estimators': 50, 'subsample': 1.0, 'learning_rate': 0.0001, 'max_depth': 3}\n",
      "0.828667 (0.031875) with: {'n_estimators': 100, 'subsample': 0.5, 'learning_rate': 0.0001, 'max_depth': 3}\n",
      "0.821667 (0.029599) with: {'n_estimators': 100, 'subsample': 0.7, 'learning_rate': 0.0001, 'max_depth': 3}\n",
      "0.765667 (0.050365) with: {'n_estimators': 100, 'subsample': 1.0, 'learning_rate': 0.0001, 'max_depth': 3}\n",
      "0.838333 (0.027799) with: {'n_estimators': 500, 'subsample': 0.5, 'learning_rate': 0.0001, 'max_depth': 3}\n",
      "0.823667 (0.029100) with: {'n_estimators': 500, 'subsample': 0.7, 'learning_rate': 0.0001, 'max_depth': 3}\n",
      "0.776000 (0.039859) with: {'n_estimators': 500, 'subsample': 1.0, 'learning_rate': 0.0001, 'max_depth': 3}\n",
      "0.501000 (0.002000) with: {'n_estimators': 10, 'subsample': 0.5, 'learning_rate': 0.0001, 'max_depth': 7}\n",
      "0.501000 (0.002000) with: {'n_estimators': 10, 'subsample': 0.7, 'learning_rate': 0.0001, 'max_depth': 7}\n",
      "0.501000 (0.002000) with: {'n_estimators': 10, 'subsample': 1.0, 'learning_rate': 0.0001, 'max_depth': 7}\n",
      "0.843667 (0.035949) with: {'n_estimators': 50, 'subsample': 0.5, 'learning_rate': 0.0001, 'max_depth': 7}\n",
      "0.848333 (0.039032) with: {'n_estimators': 50, 'subsample': 0.7, 'learning_rate': 0.0001, 'max_depth': 7}\n",
      "0.806000 (0.038601) with: {'n_estimators': 50, 'subsample': 1.0, 'learning_rate': 0.0001, 'max_depth': 7}\n",
      "0.871000 (0.034023) with: {'n_estimators': 100, 'subsample': 0.5, 'learning_rate': 0.0001, 'max_depth': 7}\n",
      "0.874667 (0.034033) with: {'n_estimators': 100, 'subsample': 0.7, 'learning_rate': 0.0001, 'max_depth': 7}\n",
      "0.808333 (0.040681) with: {'n_estimators': 100, 'subsample': 1.0, 'learning_rate': 0.0001, 'max_depth': 7}\n",
      "0.887333 (0.029114) with: {'n_estimators': 500, 'subsample': 0.5, 'learning_rate': 0.0001, 'max_depth': 7}\n",
      "0.882000 (0.033628) with: {'n_estimators': 500, 'subsample': 0.7, 'learning_rate': 0.0001, 'max_depth': 7}\n",
      "0.809000 (0.042246) with: {'n_estimators': 500, 'subsample': 1.0, 'learning_rate': 0.0001, 'max_depth': 7}\n",
      "0.501000 (0.002000) with: {'n_estimators': 10, 'subsample': 0.5, 'learning_rate': 0.0001, 'max_depth': 9}\n",
      "0.501000 (0.002000) with: {'n_estimators': 10, 'subsample': 0.7, 'learning_rate': 0.0001, 'max_depth': 9}\n",
      "0.501000 (0.002000) with: {'n_estimators': 10, 'subsample': 1.0, 'learning_rate': 0.0001, 'max_depth': 9}\n",
      "0.844667 (0.032987) with: {'n_estimators': 50, 'subsample': 0.5, 'learning_rate': 0.0001, 'max_depth': 9}\n",
      "0.839333 (0.036252) with: {'n_estimators': 50, 'subsample': 0.7, 'learning_rate': 0.0001, 'max_depth': 9}\n",
      "0.813333 (0.040394) with: {'n_estimators': 50, 'subsample': 1.0, 'learning_rate': 0.0001, 'max_depth': 9}\n",
      "0.878333 (0.033201) with: {'n_estimators': 100, 'subsample': 0.5, 'learning_rate': 0.0001, 'max_depth': 9}\n",
      "0.881000 (0.033717) with: {'n_estimators': 100, 'subsample': 0.7, 'learning_rate': 0.0001, 'max_depth': 9}\n",
      "0.816333 (0.040515) with: {'n_estimators': 100, 'subsample': 1.0, 'learning_rate': 0.0001, 'max_depth': 9}\n",
      "0.892000 (0.031599) with: {'n_estimators': 500, 'subsample': 0.5, 'learning_rate': 0.0001, 'max_depth': 9}\n",
      "0.887333 (0.034772) with: {'n_estimators': 500, 'subsample': 0.7, 'learning_rate': 0.0001, 'max_depth': 9}\n",
      "0.812667 (0.040954) with: {'n_estimators': 500, 'subsample': 1.0, 'learning_rate': 0.0001, 'max_depth': 9}\n",
      "0.821333 (0.031340) with: {'n_estimators': 10, 'subsample': 0.5, 'learning_rate': 0.001, 'max_depth': 3}\n",
      "0.818333 (0.033260) with: {'n_estimators': 10, 'subsample': 0.7, 'learning_rate': 0.001, 'max_depth': 3}\n",
      "0.765667 (0.050365) with: {'n_estimators': 10, 'subsample': 1.0, 'learning_rate': 0.001, 'max_depth': 3}\n",
      "0.833667 (0.030824) with: {'n_estimators': 50, 'subsample': 0.5, 'learning_rate': 0.001, 'max_depth': 3}\n",
      "0.823333 (0.030218) with: {'n_estimators': 50, 'subsample': 0.7, 'learning_rate': 0.001, 'max_depth': 3}\n",
      "0.776333 (0.039885) with: {'n_estimators': 50, 'subsample': 1.0, 'learning_rate': 0.001, 'max_depth': 3}\n",
      "0.836667 (0.032620) with: {'n_estimators': 100, 'subsample': 0.5, 'learning_rate': 0.001, 'max_depth': 3}\n",
      "0.821667 (0.026651) with: {'n_estimators': 100, 'subsample': 0.7, 'learning_rate': 0.001, 'max_depth': 3}\n",
      "0.783333 (0.037379) with: {'n_estimators': 100, 'subsample': 1.0, 'learning_rate': 0.001, 'max_depth': 3}\n",
      "0.846667 (0.030702) with: {'n_estimators': 500, 'subsample': 0.5, 'learning_rate': 0.001, 'max_depth': 3}\n",
      "0.838333 (0.029529) with: {'n_estimators': 500, 'subsample': 0.7, 'learning_rate': 0.001, 'max_depth': 3}\n",
      "0.818667 (0.033060) with: {'n_estimators': 500, 'subsample': 1.0, 'learning_rate': 0.001, 'max_depth': 3}\n",
      "0.851333 (0.031141) with: {'n_estimators': 10, 'subsample': 0.5, 'learning_rate': 0.001, 'max_depth': 7}\n",
      "0.857333 (0.031367) with: {'n_estimators': 10, 'subsample': 0.7, 'learning_rate': 0.001, 'max_depth': 7}\n",
      "0.807333 (0.039863) with: {'n_estimators': 10, 'subsample': 1.0, 'learning_rate': 0.001, 'max_depth': 7}\n",
      "0.878667 (0.030570) with: {'n_estimators': 50, 'subsample': 0.5, 'learning_rate': 0.001, 'max_depth': 7}\n",
      "0.879667 (0.030518) with: {'n_estimators': 50, 'subsample': 0.7, 'learning_rate': 0.001, 'max_depth': 7}\n",
      "0.807000 (0.040248) with: {'n_estimators': 50, 'subsample': 1.0, 'learning_rate': 0.001, 'max_depth': 7}\n",
      "0.887333 (0.029806) with: {'n_estimators': 100, 'subsample': 0.5, 'learning_rate': 0.001, 'max_depth': 7}\n",
      "0.885333 (0.030599) with: {'n_estimators': 100, 'subsample': 0.7, 'learning_rate': 0.001, 'max_depth': 7}\n",
      "0.811000 (0.038321) with: {'n_estimators': 100, 'subsample': 1.0, 'learning_rate': 0.001, 'max_depth': 7}\n",
      "0.891667 (0.033822) with: {'n_estimators': 500, 'subsample': 0.5, 'learning_rate': 0.001, 'max_depth': 7}\n",
      "0.889667 (0.033862) with: {'n_estimators': 500, 'subsample': 0.7, 'learning_rate': 0.001, 'max_depth': 7}\n",
      "0.829667 (0.034829) with: {'n_estimators': 500, 'subsample': 1.0, 'learning_rate': 0.001, 'max_depth': 7}\n",
      "0.854333 (0.035483) with: {'n_estimators': 10, 'subsample': 0.5, 'learning_rate': 0.001, 'max_depth': 9}\n",
      "0.863000 (0.039961) with: {'n_estimators': 10, 'subsample': 0.7, 'learning_rate': 0.001, 'max_depth': 9}\n",
      "0.814667 (0.038482) with: {'n_estimators': 10, 'subsample': 1.0, 'learning_rate': 0.001, 'max_depth': 9}\n",
      "0.887667 (0.031088) with: {'n_estimators': 50, 'subsample': 0.5, 'learning_rate': 0.001, 'max_depth': 9}\n",
      "0.882333 (0.029500) with: {'n_estimators': 50, 'subsample': 0.7, 'learning_rate': 0.001, 'max_depth': 9}\n",
      "0.814667 (0.041133) with: {'n_estimators': 50, 'subsample': 1.0, 'learning_rate': 0.001, 'max_depth': 9}\n",
      "0.889333 (0.030712) with: {'n_estimators': 100, 'subsample': 0.5, 'learning_rate': 0.001, 'max_depth': 9}\n",
      "0.888667 (0.036771) with: {'n_estimators': 100, 'subsample': 0.7, 'learning_rate': 0.001, 'max_depth': 9}\n",
      "0.809667 (0.041987) with: {'n_estimators': 100, 'subsample': 1.0, 'learning_rate': 0.001, 'max_depth': 9}\n",
      "0.895333 (0.029550) with: {'n_estimators': 500, 'subsample': 0.5, 'learning_rate': 0.001, 'max_depth': 9}\n",
      "0.894000 (0.037316) with: {'n_estimators': 500, 'subsample': 0.7, 'learning_rate': 0.001, 'max_depth': 9}\n",
      "0.818000 (0.042238) with: {'n_estimators': 500, 'subsample': 1.0, 'learning_rate': 0.001, 'max_depth': 9}\n",
      "0.819667 (0.028672) with: {'n_estimators': 10, 'subsample': 0.5, 'learning_rate': 0.01, 'max_depth': 3}\n",
      "0.821000 (0.032910) with: {'n_estimators': 10, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 3}\n",
      "0.784000 (0.035557) with: {'n_estimators': 10, 'subsample': 1.0, 'learning_rate': 0.01, 'max_depth': 3}\n",
      "0.843000 (0.027167) with: {'n_estimators': 50, 'subsample': 0.5, 'learning_rate': 0.01, 'max_depth': 3}\n",
      "0.841667 (0.031343) with: {'n_estimators': 50, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 3}\n",
      "0.819333 (0.033775) with: {'n_estimators': 50, 'subsample': 1.0, 'learning_rate': 0.01, 'max_depth': 3}\n",
      "0.854000 (0.025851) with: {'n_estimators': 100, 'subsample': 0.5, 'learning_rate': 0.01, 'max_depth': 3}\n",
      "0.845000 (0.030645) with: {'n_estimators': 100, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 3}\n",
      "0.831667 (0.030109) with: {'n_estimators': 100, 'subsample': 1.0, 'learning_rate': 0.01, 'max_depth': 3}\n",
      "0.892333 (0.024565) with: {'n_estimators': 500, 'subsample': 0.5, 'learning_rate': 0.01, 'max_depth': 3}\n",
      "0.888000 (0.028332) with: {'n_estimators': 500, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 3}\n",
      "0.876000 (0.031527) with: {'n_estimators': 500, 'subsample': 1.0, 'learning_rate': 0.01, 'max_depth': 3}\n",
      "0.865000 (0.030084) with: {'n_estimators': 10, 'subsample': 0.5, 'learning_rate': 0.01, 'max_depth': 7}\n",
      "0.868667 (0.031340) with: {'n_estimators': 10, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 7}\n",
      "0.810333 (0.039404) with: {'n_estimators': 10, 'subsample': 1.0, 'learning_rate': 0.01, 'max_depth': 7}\n",
      "0.883000 (0.033601) with: {'n_estimators': 50, 'subsample': 0.5, 'learning_rate': 0.01, 'max_depth': 7}\n",
      "0.884333 (0.034999) with: {'n_estimators': 50, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 7}\n",
      "0.828667 (0.036640) with: {'n_estimators': 50, 'subsample': 1.0, 'learning_rate': 0.01, 'max_depth': 7}\n",
      "0.895000 (0.033532) with: {'n_estimators': 100, 'subsample': 0.5, 'learning_rate': 0.01, 'max_depth': 7}\n",
      "0.891000 (0.033734) with: {'n_estimators': 100, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 7}\n",
      "0.847667 (0.033373) with: {'n_estimators': 100, 'subsample': 1.0, 'learning_rate': 0.01, 'max_depth': 7}\n",
      "0.927333 (0.023982) with: {'n_estimators': 500, 'subsample': 0.5, 'learning_rate': 0.01, 'max_depth': 7}\n",
      "0.921333 (0.027160) with: {'n_estimators': 500, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 7}\n",
      "0.888333 (0.027930) with: {'n_estimators': 500, 'subsample': 1.0, 'learning_rate': 0.01, 'max_depth': 7}\n",
      "0.867667 (0.026386) with: {'n_estimators': 10, 'subsample': 0.5, 'learning_rate': 0.01, 'max_depth': 9}\n",
      "0.864667 (0.035559) with: {'n_estimators': 10, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 9}\n",
      "0.807000 (0.038972) with: {'n_estimators': 10, 'subsample': 1.0, 'learning_rate': 0.01, 'max_depth': 9}\n",
      "0.888000 (0.030737) with: {'n_estimators': 50, 'subsample': 0.5, 'learning_rate': 0.01, 'max_depth': 9}\n",
      "0.888667 (0.031423) with: {'n_estimators': 50, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 9}\n",
      "0.817667 (0.040408) with: {'n_estimators': 50, 'subsample': 1.0, 'learning_rate': 0.01, 'max_depth': 9}\n",
      "0.898000 (0.033048) with: {'n_estimators': 100, 'subsample': 0.5, 'learning_rate': 0.01, 'max_depth': 9}\n",
      "0.893667 (0.033565) with: {'n_estimators': 100, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 9}\n",
      "0.823000 (0.040295) with: {'n_estimators': 100, 'subsample': 1.0, 'learning_rate': 0.01, 'max_depth': 9}\n",
      "0.926000 (0.022886) with: {'n_estimators': 500, 'subsample': 0.5, 'learning_rate': 0.01, 'max_depth': 9}\n",
      "0.921333 (0.026859) with: {'n_estimators': 500, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 9}\n",
      "0.837667 (0.038888) with: {'n_estimators': 500, 'subsample': 1.0, 'learning_rate': 0.01, 'max_depth': 9}\n",
      "0.844000 (0.034755) with: {'n_estimators': 10, 'subsample': 0.5, 'learning_rate': 0.1, 'max_depth': 3}\n",
      "0.843000 (0.034634) with: {'n_estimators': 10, 'subsample': 0.7, 'learning_rate': 0.1, 'max_depth': 3}\n",
      "0.834333 (0.035215) with: {'n_estimators': 10, 'subsample': 1.0, 'learning_rate': 0.1, 'max_depth': 3}\n",
      "0.885333 (0.028643) with: {'n_estimators': 50, 'subsample': 0.5, 'learning_rate': 0.1, 'max_depth': 3}\n",
      "0.890667 (0.029890) with: {'n_estimators': 50, 'subsample': 0.7, 'learning_rate': 0.1, 'max_depth': 3}\n",
      "0.877000 (0.031965) with: {'n_estimators': 50, 'subsample': 1.0, 'learning_rate': 0.1, 'max_depth': 3}\n",
      "0.907000 (0.024373) with: {'n_estimators': 100, 'subsample': 0.5, 'learning_rate': 0.1, 'max_depth': 3}\n",
      "0.902333 (0.025178) with: {'n_estimators': 100, 'subsample': 0.7, 'learning_rate': 0.1, 'max_depth': 3}\n",
      "0.898667 (0.026039) with: {'n_estimators': 100, 'subsample': 1.0, 'learning_rate': 0.1, 'max_depth': 3}\n",
      "0.924333 (0.020875) with: {'n_estimators': 500, 'subsample': 0.5, 'learning_rate': 0.1, 'max_depth': 3}\n",
      "0.929333 (0.022247) with: {'n_estimators': 500, 'subsample': 0.7, 'learning_rate': 0.1, 'max_depth': 3}\n",
      "0.921333 (0.022611) with: {'n_estimators': 500, 'subsample': 1.0, 'learning_rate': 0.1, 'max_depth': 3}\n",
      "0.873667 (0.032365) with: {'n_estimators': 10, 'subsample': 0.5, 'learning_rate': 0.1, 'max_depth': 7}\n",
      "0.872333 (0.023850) with: {'n_estimators': 10, 'subsample': 0.7, 'learning_rate': 0.1, 'max_depth': 7}\n",
      "0.842667 (0.035702) with: {'n_estimators': 10, 'subsample': 1.0, 'learning_rate': 0.1, 'max_depth': 7}\n",
      "0.905667 (0.025896) with: {'n_estimators': 50, 'subsample': 0.5, 'learning_rate': 0.1, 'max_depth': 7}\n",
      "0.907333 (0.026023) with: {'n_estimators': 50, 'subsample': 0.7, 'learning_rate': 0.1, 'max_depth': 7}\n",
      "0.891667 (0.029624) with: {'n_estimators': 50, 'subsample': 1.0, 'learning_rate': 0.1, 'max_depth': 7}\n",
      "0.927333 (0.024778) with: {'n_estimators': 100, 'subsample': 0.5, 'learning_rate': 0.1, 'max_depth': 7}\n",
      "0.928000 (0.024605) with: {'n_estimators': 100, 'subsample': 0.7, 'learning_rate': 0.1, 'max_depth': 7}\n",
      "0.909667 (0.028137) with: {'n_estimators': 100, 'subsample': 1.0, 'learning_rate': 0.1, 'max_depth': 7}\n",
      "0.937333 (0.020199) with: {'n_estimators': 500, 'subsample': 0.5, 'learning_rate': 0.1, 'max_depth': 7}\n",
      "0.937667 (0.020142) with: {'n_estimators': 500, 'subsample': 0.7, 'learning_rate': 0.1, 'max_depth': 7}\n",
      "0.908000 (0.025839) with: {'n_estimators': 500, 'subsample': 1.0, 'learning_rate': 0.1, 'max_depth': 7}\n",
      "0.884667 (0.030686) with: {'n_estimators': 10, 'subsample': 0.5, 'learning_rate': 0.1, 'max_depth': 9}\n",
      "0.880000 (0.032822) with: {'n_estimators': 10, 'subsample': 0.7, 'learning_rate': 0.1, 'max_depth': 9}\n",
      "0.824667 (0.039320) with: {'n_estimators': 10, 'subsample': 1.0, 'learning_rate': 0.1, 'max_depth': 9}\n",
      "0.915667 (0.026890) with: {'n_estimators': 50, 'subsample': 0.5, 'learning_rate': 0.1, 'max_depth': 9}\n",
      "0.913333 (0.024220) with: {'n_estimators': 50, 'subsample': 0.7, 'learning_rate': 0.1, 'max_depth': 9}\n",
      "0.835667 (0.038921) with: {'n_estimators': 50, 'subsample': 1.0, 'learning_rate': 0.1, 'max_depth': 9}\n",
      "0.930000 (0.022714) with: {'n_estimators': 100, 'subsample': 0.5, 'learning_rate': 0.1, 'max_depth': 9}\n",
      "0.929667 (0.024392) with: {'n_estimators': 100, 'subsample': 0.7, 'learning_rate': 0.1, 'max_depth': 9}\n",
      "0.848667 (0.042564) with: {'n_estimators': 100, 'subsample': 1.0, 'learning_rate': 0.1, 'max_depth': 9}\n",
      "0.942000 (0.026026) with: {'n_estimators': 500, 'subsample': 0.5, 'learning_rate': 0.1, 'max_depth': 9}\n",
      "0.935333 (0.022073) with: {'n_estimators': 500, 'subsample': 0.7, 'learning_rate': 0.1, 'max_depth': 9}\n",
      "0.841667 (0.038713) with: {'n_estimators': 500, 'subsample': 1.0, 'learning_rate': 0.1, 'max_depth': 9}\n",
      "0.825667 (0.044793) with: {'n_estimators': 10, 'subsample': 0.5, 'learning_rate': 1.0, 'max_depth': 3}\n",
      "0.844333 (0.027497) with: {'n_estimators': 10, 'subsample': 0.7, 'learning_rate': 1.0, 'max_depth': 3}\n",
      "0.851000 (0.032508) with: {'n_estimators': 10, 'subsample': 1.0, 'learning_rate': 1.0, 'max_depth': 3}\n",
      "0.828333 (0.035429) with: {'n_estimators': 50, 'subsample': 0.5, 'learning_rate': 1.0, 'max_depth': 3}\n",
      "0.863667 (0.035346) with: {'n_estimators': 50, 'subsample': 0.7, 'learning_rate': 1.0, 'max_depth': 3}\n",
      "0.894000 (0.033552) with: {'n_estimators': 50, 'subsample': 1.0, 'learning_rate': 1.0, 'max_depth': 3}\n",
      "0.837667 (0.033610) with: {'n_estimators': 100, 'subsample': 0.5, 'learning_rate': 1.0, 'max_depth': 3}\n",
      "0.877000 (0.031528) with: {'n_estimators': 100, 'subsample': 0.7, 'learning_rate': 1.0, 'max_depth': 3}\n",
      "0.906667 (0.031491) with: {'n_estimators': 100, 'subsample': 1.0, 'learning_rate': 1.0, 'max_depth': 3}\n",
      "0.829000 (0.074562) with: {'n_estimators': 500, 'subsample': 0.5, 'learning_rate': 1.0, 'max_depth': 3}\n",
      "0.893000 (0.034500) with: {'n_estimators': 500, 'subsample': 0.7, 'learning_rate': 1.0, 'max_depth': 3}\n",
      "0.909333 (0.031680) with: {'n_estimators': 500, 'subsample': 1.0, 'learning_rate': 1.0, 'max_depth': 3}\n",
      "0.807333 (0.031569) with: {'n_estimators': 10, 'subsample': 0.5, 'learning_rate': 1.0, 'max_depth': 7}\n",
      "0.848667 (0.027459) with: {'n_estimators': 10, 'subsample': 0.7, 'learning_rate': 1.0, 'max_depth': 7}\n",
      "0.884667 (0.029152) with: {'n_estimators': 10, 'subsample': 1.0, 'learning_rate': 1.0, 'max_depth': 7}\n",
      "0.828333 (0.047313) with: {'n_estimators': 50, 'subsample': 0.5, 'learning_rate': 1.0, 'max_depth': 7}\n",
      "0.889333 (0.028976) with: {'n_estimators': 50, 'subsample': 0.7, 'learning_rate': 1.0, 'max_depth': 7}\n",
      "0.901000 (0.033840) with: {'n_estimators': 50, 'subsample': 1.0, 'learning_rate': 1.0, 'max_depth': 7}\n",
      "0.825333 (0.056997) with: {'n_estimators': 100, 'subsample': 0.5, 'learning_rate': 1.0, 'max_depth': 7}\n",
      "0.893000 (0.026097) with: {'n_estimators': 100, 'subsample': 0.7, 'learning_rate': 1.0, 'max_depth': 7}\n",
      "0.897333 (0.032568) with: {'n_estimators': 100, 'subsample': 1.0, 'learning_rate': 1.0, 'max_depth': 7}\n",
      "0.761667 (0.114104) with: {'n_estimators': 500, 'subsample': 0.5, 'learning_rate': 1.0, 'max_depth': 7}\n",
      "0.889667 (0.035210) with: {'n_estimators': 500, 'subsample': 0.7, 'learning_rate': 1.0, 'max_depth': 7}\n",
      "0.903000 (0.029147) with: {'n_estimators': 500, 'subsample': 1.0, 'learning_rate': 1.0, 'max_depth': 7}\n",
      "0.810667 (0.044194) with: {'n_estimators': 10, 'subsample': 0.5, 'learning_rate': 1.0, 'max_depth': 9}\n",
      "0.859000 (0.031586) with: {'n_estimators': 10, 'subsample': 0.7, 'learning_rate': 1.0, 'max_depth': 9}\n",
      "0.878000 (0.032600) with: {'n_estimators': 10, 'subsample': 1.0, 'learning_rate': 1.0, 'max_depth': 9}\n",
      "0.850333 (0.039597) with: {'n_estimators': 50, 'subsample': 0.5, 'learning_rate': 1.0, 'max_depth': 9}\n",
      "0.886000 (0.032910) with: {'n_estimators': 50, 'subsample': 0.7, 'learning_rate': 1.0, 'max_depth': 9}\n",
      "0.880667 (0.029059) with: {'n_estimators': 50, 'subsample': 1.0, 'learning_rate': 1.0, 'max_depth': 9}\n",
      "0.831667 (0.063373) with: {'n_estimators': 100, 'subsample': 0.5, 'learning_rate': 1.0, 'max_depth': 9}\n",
      "0.880667 (0.027158) with: {'n_estimators': 100, 'subsample': 0.7, 'learning_rate': 1.0, 'max_depth': 9}\n",
      "0.885333 (0.031112) with: {'n_estimators': 100, 'subsample': 1.0, 'learning_rate': 1.0, 'max_depth': 9}\n",
      "0.788333 (0.127498) with: {'n_estimators': 500, 'subsample': 0.5, 'learning_rate': 1.0, 'max_depth': 9}\n",
      "0.877333 (0.031295) with: {'n_estimators': 500, 'subsample': 0.7, 'learning_rate': 1.0, 'max_depth': 9}\n",
      "0.883333 (0.029423) with: {'n_estimators': 500, 'subsample': 1.0, 'learning_rate': 1.0, 'max_depth': 9}\n"
     ]
    }
   ],
   "source": [
    "# example of grid searching key hyperparameters for gradient boosting on a classification dataset\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "\n",
    "# define the model with default hyperparameters\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "# define the grid of values to search\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [10, 50, 100, 500]\n",
    "grid['learning_rate'] = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "grid['subsample'] = [0.5, 0.7, 1.0]\n",
    "grid['max_depth'] = [3, 7, 9]\n",
    "\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# define the grid search procedure\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy')\n",
    "\n",
    "# execute the grid search\n",
    "grid_result = grid_search.fit(X, y)\n",
    "\n",
    "# summarize the best score and configuration\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# summarize all scores that were evaluated\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
